{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d19fd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm  # \n",
    "import os\n",
    "from pathlib import Path\n",
    "# \n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "print(f\"cuda:{torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        device = torch.device(f\"cuda:{i}\")\n",
    "        properties = torch.cuda.get_device_properties(device)\n",
    "        print(f\"GPU {i}:{properties.name}:{properties.total_memory/1024/1024/1024:.2f}GB\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "## ###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a23ad39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rand_sparse_matrix(rows, cols, connection_rate):\n",
    "\n",
    "    assert 0 < connection_rate <= 1, \"The connection rate must be between (0,1]\"\n",
    "\n",
    "    # Calculate the number of non-zero elements\n",
    "    num_elements = rows * cols\n",
    "    num_nonzero = int(num_elements * connection_rate)\n",
    "\n",
    "    # Randomly generate the position of non-zero elements\n",
    "    row_indices = torch.randint(0, rows, (num_nonzero,))\n",
    "    col_indices = torch.randint(0, cols, (num_nonzero,))\n",
    "\n",
    "    # Stack row and column indices into a two-dimensional tensor\n",
    "    indices = torch.stack((row_indices, col_indices))\n",
    "\n",
    "    # Randomly generate values for non-zero elements\n",
    "    values = torch.rand(num_nonzero)*2-1\n",
    "\n",
    "    # Create Sparse Matrix\n",
    "    sparse_matrix = torch.sparse_coo_tensor(indices, values, (rows, cols))\n",
    "\n",
    "    return sparse_matrix\n",
    "\n",
    "\n",
    "def Aindx2Nrange(numnodes, div, Aindx):\n",
    "    node_indx = []\n",
    "    nodes_per_div = numnodes // abs(div)\n",
    "    if isinstance(Aindx, list) == False: Aindx = [Aindx]\n",
    "\n",
    "    for indx in Aindx:\n",
    "        # Calculate the start and end indices for the specified division\n",
    "        start_idx = (indx-1) * nodes_per_div\n",
    "        end_idx = indx * nodes_per_div - 1\n",
    "        \n",
    "        # Create the output range\n",
    "        node_indx.extend(range(start_idx, end_idx + 1))\n",
    "\n",
    "\n",
    "    return node_indx\n",
    "\n",
    "\n",
    "def adam_update(m, v, dw, beta1, beta2, t, epsilon=1e-8):\n",
    "    # Update first-order moment estimation\n",
    "    m = beta1 * m + (1 - beta1) * dw\n",
    "    v = beta2 * v + (1 - beta2) * (dw ** 2)\n",
    "    \n",
    "    # First and Second Order Moment Estimation for Deviation Correction Calculation\n",
    "    m_corr = m / (1 - beta1 ** t)\n",
    "    v_corr = v / (1 - beta2 ** t)\n",
    "    \n",
    "    # Calculate update value\n",
    "    update = m_corr / (torch.sqrt(v_corr) + epsilon)\n",
    "    \n",
    "    return update, m, v\n",
    "\n",
    "def linear(x):\n",
    "    return x\n",
    "\n",
    "def linear_d(x):\n",
    "    return torch.ones_like(x)\n",
    "\n",
    "def tanh(x):\n",
    "    return torch.tanh(x)\n",
    "\n",
    "def tanh_d(x):\n",
    "    return 1 - torch.tanh(x) ** 2  \n",
    "\n",
    "def hard_sigmoid(x):\n",
    "    return torch.clamp(x,0,1)\n",
    "\n",
    "def hard_sigmoid_d(x):\n",
    "    return torch.where((x >= 0) & (x <= 1), torch.ones_like(x), torch.zeros_like(x))\n",
    "\n",
    "def relu6(x):\n",
    "    return torch.max(torch.min(x, torch.ones_like(x) * 6), torch.zeros_like(x))  \n",
    "\n",
    "def relu6_d(x):\n",
    "    return torch.where((x > 0) & (x <= 6), torch.ones_like(x), torch.zeros_like(x))\n",
    "\n",
    "def softmax(x):\n",
    "    x = x - torch.max(x, dim=1, keepdim=True)[0]  # Subtract the maximum value to prevent overflow\n",
    "    return torch.exp(x) / torch.sum(torch.exp(x), dim=1, keepdim=True)\n",
    "\n",
    "\n",
    "\n",
    "# One-hot \n",
    "def one_hot(labels, n_out):\n",
    "    one_hot_labels = torch.zeros(labels.size(0), n_out)\n",
    "    one_hot_labels[torch.arange(labels.size(0)), labels] = 1\n",
    "    return one_hot_labels\n",
    "\n",
    "def cross_entropy_loss(output, target):\n",
    "    epsilon = 1e-8  # avoid log(0)\n",
    "    output = torch.clamp(output, epsilon, 1. - epsilon)  # Limit the output to [epsilon, 1-epsilon] \n",
    "    return -torch.mean(torch.sum(target * torch.log(output), dim=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feac684",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FRNN_ML4(torch.nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(FRNN_ML4, self).__init__()\n",
    "        self.device = config.device\n",
    "\n",
    "        self.f = config.f\n",
    "        self.feedbackLearning = config.feedbackLearning\n",
    "        self.RNNLearning = config.RNNLearning\n",
    "        self.RNNBiasLearning = config.RNNBiasLearning\n",
    "\n",
    "        self.H_size = config.H_size\n",
    "        self.NperU = config.NperU\n",
    "        self.NU = config.NU \n",
    "\n",
    "        self.t2sta = config.t2sta\n",
    "        self.RNNSR = config.RNNSR\n",
    "        self.Feedforwardsc = config.Feedforwardsc\n",
    "        self.Feedbacksc = config.Feedbacksc\n",
    "        self.batch_size = config.batch_size  # \n",
    "\n",
    "        # \n",
    "        self.W3L = True\n",
    "\n",
    "        # Wr\n",
    "        self.Wr_1 = rand_sparse_matrix(config.H_size, config.H_size, config.RNNCR).to_dense()\n",
    "        self.Wr_1_s = self.Wr_1 !=0 \n",
    "        self.Wr_1 = self.Wr_1 / torch.abs( torch.linalg.eigvals(self.Wr_1)).max() * self.RNNSR \n",
    "        self.Wr_1 = self.Wr_1.to(self.device)\n",
    "        self.bias_1 = torch.zeros(config.H_size,device=self.device) \n",
    "        self.Wr_1_s = self.Wr_1_s.to(self.device) \n",
    "\n",
    "\n",
    "        self.Wr_2 = rand_sparse_matrix(config.H_size, config.H_size, config.RNNCR).to_dense()\n",
    "        self.Wr_2_s = self.Wr_2 !=0\n",
    "        self.Wr_2 = self.Wr_2 / torch.abs( torch.linalg.eigvals(self.Wr_2)).max() * self.RNNSR\n",
    "        self.Wr_2 = self.Wr_2.to(self.device)\n",
    "        self.bias_2 = torch.zeros(config.H_size,device=self.device)\n",
    "        self.Wr_2_s = self.Wr_2_s.to(self.device) \n",
    "\n",
    "        self.Wr_3 = rand_sparse_matrix(config.H_size, config.H_size, config.RNNCR).to_dense()\n",
    "        self.Wr_3_s = self.Wr_3 !=0\n",
    "        self.Wr_3 = self.Wr_3 / torch.abs( torch.linalg.eigvals(self.Wr_3)).max() * self.RNNSR\n",
    "        self.Wr_3 = self.Wr_3.to(self.device)\n",
    "        self.bias_3 = torch.zeros(config.H_size,device=self.device) \n",
    "        self.Wr_3_s = self.Wr_3_s.to(self.device) \n",
    "\n",
    "        self.Wr_4 = rand_sparse_matrix(config.H_size, config.H_size, config.RNNCR).to_dense()\n",
    "        self.Wr_4_s = self.Wr_4 !=0\n",
    "        self.Wr_4 = self.Wr_4 / torch.abs( torch.linalg.eigvals(self.Wr_4)).max() * self.RNNSR\n",
    "        self.Wr_4 = self.Wr_4.to(self.device)\n",
    "        self.bias_4 = torch.zeros(config.H_size,device=self.device)  \n",
    "        self.Wr_4_s = self.Wr_4_s.to(self.device) \n",
    "\n",
    "        #\n",
    "        self.Wb_f_1 = torch.randn(config.num_classes, config.NperU,device=self.device) * self.Feedbacksc \n",
    "        self.Wb_f_2 = torch.randn(config.num_classes, config.NperU,device=self.device) * self.Feedbacksc  \n",
    "        self.Wb_f_3 = torch.randn(config.num_classes, config.NperU,device=self.device) * self.Feedbacksc  \n",
    "\n",
    "        self.Wb_1 = torch.randn(config.NperU, config.NperU,device=self.device) * self.Feedbacksc\n",
    "        self.Wb_2 = torch.randn(config.NperU, config.NperU,device=self.device) * self.Feedbacksc\n",
    "        self.Wb_3 = torch.randn(config.NperU, config.NperU,device=self.device) * self.Feedbacksc\n",
    "        self.Wb_4 = torch.randn(config.NperU, config.NperU,device=self.device) * self.Feedbacksc\n",
    "\n",
    "        self.WinX_1 = torch.randn(config.input_size, config.NperU,device=self.device) * self.Feedforwardsc\n",
    "        self.WinX_2 = torch.randn(config.input_size, config.NperU,device=self.device) * self.Feedforwardsc\n",
    "        self.WinX_3 = torch.randn(config.input_size, config.NperU,device=self.device) * self.Feedforwardsc\n",
    "\n",
    "        self.Win_1 = torch.randn(config.NperU, config.NperU,device=self.device) * self.Feedforwardsc\n",
    "        self.Win_2 = torch.randn(config.NperU, config.NperU,device=self.device) * self.Feedforwardsc  \n",
    "        self.Win_3 = torch.randn(config.NperU, config.NperU,device=self.device) * self.Feedforwardsc\n",
    "        self.Win_4 = torch.randn(config.NperU, config.NperU,device=self.device) * self.Feedforwardsc  \n",
    "\n",
    "        self.Wout_1 = torch.randn(config.NperU, config.num_classes,device=self.device) * self.Feedforwardsc\n",
    "        self.Wout_2 = torch.randn(config.NperU, config.num_classes,device=self.device) * self.Feedforwardsc\n",
    "        self.Wout_3 = torch.randn(config.NperU, config.num_classes,device=self.device) * self.Feedforwardsc\n",
    "        self.bias_f_1 = torch.zeros(config.num_classes,device=self.device)\n",
    "        self.bias_f_2 = torch.zeros(config.num_classes,device=self.device)\n",
    "        self.bias_f_3 = torch.zeros(config.num_classes,device=self.device)\n",
    "\n",
    "        #\n",
    "        self.beta1 = 1\n",
    "        self.gamma1 = config.gamma1\n",
    "        self.alpha1 = config.alpha1  # \n",
    "        self.lambda1 = config.lambda1\n",
    "\n",
    "        # Adam\n",
    "        # \n",
    "        self.opt_m_Wr_1, self.opt_v_Wr_1 = torch.zeros_like(self.Wr_1), torch.zeros_like(self.Wr_1)\n",
    "        self.opt_m_b_1, self.opt_v_b_1 = torch.zeros_like(self.bias_1), torch.zeros_like(self.bias_1)\n",
    "        self.opt_m_Wr_2, self.opt_v_Wr_2 = torch.zeros_like(self.Wr_2), torch.zeros_like(self.Wr_2)\n",
    "        self.opt_m_b_2, self.opt_v_b_2 = torch.zeros_like(self.bias_2), torch.zeros_like(self.bias_2)\n",
    "        self.opt_m_Wr_3, self.opt_v_Wr_3 = torch.zeros_like(self.Wr_3), torch.zeros_like(self.Wr_3)  \n",
    "        self.opt_m_b_3, self.opt_v_b_3 = torch.zeros_like(self.bias_3), torch.zeros_like(self.bias_3)\n",
    "        self.opt_m_Wr_4, self.opt_v_Wr_4 = torch.zeros_like(self.Wr_4), torch.zeros_like(self.Wr_4)  \n",
    "        self.opt_m_b_4, self.opt_v_b_4 = torch.zeros_like(self.bias_4), torch.zeros_like(self.bias_4)  \n",
    "\n",
    "        self.opt_m_WinX_1, self.opt_v_WinX_1 = torch.zeros_like(self.WinX_1), torch.zeros_like(self.WinX_1)\n",
    "        self.opt_m_WinX_2, self.opt_v_WinX_2 = torch.zeros_like(self.WinX_2), torch.zeros_like(self.WinX_2)\n",
    "\n",
    "        self.opt_m_Win_1, self.opt_v_Win_1 = torch.zeros_like(self.Win_1), torch.zeros_like(self.Win_1)\n",
    "        self.opt_m_Win_2, self.opt_v_Win_2 = torch.zeros_like(self.Win_2), torch.zeros_like(self.Win_2)  \n",
    "        self.opt_m_Win_3, self.opt_v_Win_3 = torch.zeros_like(self.Win_3), torch.zeros_like(self.Win_3)\n",
    "        self.opt_m_Win_4, self.opt_v_Win_4 = torch.zeros_like(self.Win_4), torch.zeros_like(self.Win_4) \n",
    "\n",
    "\n",
    "        # out\n",
    "        self.opt_m_Wout_1, self.opt_v_Wout_1 = torch.zeros_like(self.Wout_1), torch.zeros_like(self.Wout_1)\n",
    "        self.opt_m_Wout_2, self.opt_v_Wout_2 = torch.zeros_like(self.Wout_2), torch.zeros_like(self.Wout_2)\n",
    "        self.opt_m_bias_f_1, self.opt_v_bias_f_1 = torch.zeros_like(self.bias_f_1), torch.zeros_like(self.bias_f_1)\n",
    "        self.opt_m_bias_f_2, self.opt_v_bias_f_2 = torch.zeros_like(self.bias_f_2), torch.zeros_like(self.bias_f_2)\n",
    "        \n",
    "\n",
    "        self.opt_beta1, self.opt_beta2 = 0.9, 0.999\n",
    "        self.opt_epsilon = 1e-8\n",
    "        self.opt_eta = config.learning_rate\n",
    "        self.opt_t1 = 0  \n",
    "        self.opt_t2 = 0  \n",
    "\n",
    "    def forward1(self, x):\n",
    "        bs = x.size(0)\n",
    "        self.z_1 = torch.zeros(bs , self.bias_1.size(0),device=self.device)\n",
    "        self.cbias_1 = torch.zeros(bs , self.bias_1.size(0),device=self.device)\n",
    "        self.cbias_1[:, Aindx2Nrange(self.H_size, self.NU, 1)] = x.mm(self.WinX_1) \n",
    "        self.z_1 = self.It2sta(self.Wr_1, self.z_1, self.bias_1 + self.cbias_1, self.t2sta)\n",
    "\n",
    "        self.z_2 = torch.zeros(bs , self.bias_2.size(0),device=self.device)\n",
    "        self.cbias_2 = torch.zeros(bs , self.bias_2.size(0),device=self.device)\n",
    "        self.cbias_2[:, Aindx2Nrange(self.H_size, self.NU, 1)] = self.z_1[:, Aindx2Nrange(self.H_size, self.NU, 3)].mm(self.Win_1) \n",
    "        self.z_2 = self.It2sta(self.Wr_2, self.z_2, self.bias_2 + self.cbias_2, self.t2sta)\n",
    "\n",
    "        self.zfh1 = self.z_2[:, Aindx2Nrange(self.H_size, self.NU, 3)].mm(self.Wout_1) + self.bias_f_1\n",
    "        self.zf1 = softmax(self.zfh1)\n",
    "        # self.zf1 = self.f(self.zfh1)\n",
    "        return self.zf1\n",
    "    \n",
    "    def forward2(self, x):\n",
    "        bs = x.size(0)\n",
    "\n",
    "        self.z_3 = torch.zeros(bs , self.bias_3.size(0),device=self.device) \n",
    "        self.cbias_3 = torch.zeros(bs , self.bias_3.size(0),device=self.device)\n",
    "        self.cbias_3[:, Aindx2Nrange(self.H_size, self.NU, 5)] = x.mm(self.WinX_2) \n",
    "        self.z_3 = self.It2sta(self.Wr_3, self.z_3, self.bias_3 + self.cbias_3, self.t2sta)\n",
    "\n",
    "        self.z_4 = torch.zeros(bs , self.bias_4.size(0),device=self.device) \n",
    "        self.cbias_4 = torch.zeros(bs , self.bias_4.size(0),device=self.device)\n",
    "        self.cbias_4[:, Aindx2Nrange(self.H_size, self.NU, 1)] = self.z_3[:, Aindx2Nrange(self.H_size, self.NU, 2)].mm(self.Win_3)  # \n",
    "        self.z_4 = self.It2sta(self.Wr_4, self.z_4, self.bias_4 + self.cbias_4, self.t2sta)\n",
    "\n",
    "        self.zfh2 = self.z_4[:, Aindx2Nrange(self.H_size, self.NU, 3)].mm(self.Wout_2) + self.bias_f_2\n",
    "        self.zf2 = softmax(self.zfh2)\n",
    "        # self.zf2 = self.f(self.zfh2)\n",
    "        return self.zf2\n",
    "\n",
    "    def backward1(self, x, y, output):\n",
    "        bs = x.size(0)   \n",
    "\n",
    "        self.e_f_1 = output - y\n",
    "        # L2\n",
    "        self.cbias_2[:, Aindx2Nrange(self.H_size, self.NU, 4)] = -self.beta1 * self.e_f_1.mm(self.Wb_f_1)\n",
    "        self.y_2 = self.z_2\n",
    "        self.y_2 = self.It2sta(self.Wr_2, self.y_2, self.bias_2 + self.cbias_2, self.t2sta)\n",
    "        self.e_2 = self.z_2 - self.y_2\n",
    "\n",
    "        # L4\n",
    "        self.z_4 = torch.zeros(bs , self.bias_4.size(0),device=self.device)\n",
    "        self.cbias_4 = torch.zeros(bs , self.bias_4.size(0),device=self.device)\n",
    "        self.z_4 = self.It2sta(self.Wr_4, self.z_4, self.bias_4 + self.cbias_4, self.t2sta) #It2staf\n",
    "\n",
    "        self.cbias_4[:, Aindx2Nrange(self.H_size, self.NU, 5)] = -self.beta1 * self.e_f_1.mm(self.Wb_f_3) \n",
    "        self.y_4 = self.z_4\n",
    "        self.y_4 = self.It2sta(self.Wr_4, self.y_4, self.bias_4 + self.cbias_4, self.t2sta) #\n",
    "        self.e_4 = self.z_4 - self.y_4\n",
    "\n",
    "        # L3\n",
    "        self.z_3 = torch.zeros(bs , self.bias_3.size(0),device=self.device)\n",
    "        self.cbias_3 = torch.zeros(bs , self.bias_3.size(0),device=self.device)\n",
    "        self.z_3 = self.It2sta(self.Wr_3, self.z_3, self.bias_3 + self.cbias_3, self.t2sta) #\n",
    "\n",
    "        self.cbias_3[:, Aindx2Nrange(self.H_size, self.NU, 3)] = -self.beta1 * self.e_4[:, Aindx2Nrange(self.H_size, self.NU, 6)].mm(self.Wb_3)\n",
    "        self.y_3 = self.z_3\n",
    "        self.y_3 = self.It2sta(self.Wr_3, self.y_3, self.bias_3 + self.cbias_3, self.t2sta) #\n",
    "        self.e_3 = self.z_3 - self.y_3\n",
    "\n",
    "        # L1\n",
    "        self.cbias_1[:, Aindx2Nrange(self.H_size, self.NU, 6)] = -self.beta1 * self.e_3[:, Aindx2Nrange(self.H_size, self.NU, 4)].mm(self.Wb_2)\n",
    "        self.y_1 = self.z_1\n",
    "        self.y_1 = self.It2sta(self.Wr_1, self.y_1, self.bias_1 + self.cbias_1, self.t2sta)\n",
    "        self.e_1 = self.z_1 - self.y_1\n",
    "\n",
    "        ## \n",
    "        self.dWinX_1 = x.t().mm(self.e_1[:, Aindx2Nrange(self.H_size, self.NU, 1)]) / self.batch_size\n",
    "        self.dWin_1 = self.z_1[:, Aindx2Nrange(self.H_size, self.NU, 3)].t().mm(self.e_2[:, Aindx2Nrange(self.H_size, self.NU, 1)]) / self.batch_size\n",
    "        self.dWout_1 = self.z_2[:, Aindx2Nrange(self.H_size, self.NU, 3)].t().mm(self.e_f_1) / self.batch_size\n",
    "        self.dbias_f_1 = self.e_f_1.sum(0) / self.batch_size\n",
    "\n",
    "        if self.RNNLearning: \n",
    "            self.dWr_1 = self.z_1.t().mm(self.e_1) / self.batch_size\n",
    "            self.dWr_2 = self.z_2.t().mm(self.e_2) / self.batch_size\n",
    "            \n",
    "        if self.RNNBiasLearning:\n",
    "            self.dbias_1 = self.e_1.sum(0) / self.batch_size\n",
    "            self.dbias_2 = self.e_2.sum(0) / self.batch_size\n",
    "                \n",
    "        self.opt_t1 += 1\n",
    "        dWinX_1, self.opt_m_WinX_1, self.opt_v_WinX_1    = adam_update(self.opt_m_WinX_1, self.opt_v_WinX_1, self.dWinX_1, self.opt_beta1, self.opt_beta2, self.opt_t1)\n",
    "        self.WinX_1 -= self.opt_eta * dWinX_1 + self.WinX_1 * self.lambda1  \n",
    "\n",
    "        dWin_1, self.opt_m_Win_1, self.opt_v_Win_1      = adam_update(self.opt_m_Win_1, self.opt_v_Win_1,   self.dWin_1, self.opt_beta1, self.opt_beta2, self.opt_t1)\n",
    "        self.Win_1 -= self.opt_eta * dWin_1 + self.Win_1 * self.lambda1 \n",
    "\n",
    "        dWout_1, self.opt_m_Wout_1, self.opt_v_Wout_1    = adam_update(self.opt_m_Wout_1, self.opt_v_Wout_1, self.dWout_1, self.opt_beta1, self.opt_beta2, self.opt_t1)\n",
    "        self.Wout_1 -= self.opt_eta * dWout_1 + self.Wout_1 * self.lambda1 \n",
    "\n",
    "\n",
    "\n",
    "        if self.RNNLearning: \n",
    "            dWr_1, self.opt_m_Wr_1, self.opt_v_Wr_1          = adam_update(self.opt_m_Wr_1, self.opt_v_Wr_1,     self.dWr_1, self.opt_beta1, self.opt_beta2, self.opt_t1)\n",
    "            self.Wr_1 -= self.opt_eta * dWr_1 * self.Wr_1_s * self.alpha1 + self.Wr_1 * self.lambda1 \n",
    "            dWr_2, self.opt_m_Wr_2, self.opt_v_Wr_2         = adam_update(self.opt_m_Wr_2, self.opt_v_Wr_2,     self.dWr_2, self.opt_beta1, self.opt_beta2, self.opt_t1)\n",
    "            self.Wr_2 -= self.opt_eta * dWr_2 * self.Wr_2_s * self.alpha1 + self.Wr_2 * self.lambda1 \n",
    "\n",
    "        if self.RNNBiasLearning:\n",
    "            dbias_1, self.opt_m_b_1, self.opt_v_b_1          = adam_update(self.opt_m_b_1, self.opt_v_b_1,       self.dbias_1, self.opt_beta1, self.opt_beta2, self.opt_t1)\n",
    "            self.bias_1 -= self.opt_eta * dbias_1 + self.bias_1 * self.lambda1\n",
    "            dbias_2, self.opt_m_b_2, self.opt_v_b_2         = adam_update(self.opt_m_b_2, self.opt_v_b_2,       self.dbias_2, self.opt_beta1, self.opt_beta2, self.opt_t1)\n",
    "            self.bias_2 -= self.opt_eta * dbias_2 + self.bias_2 * self.lambda1 \n",
    "            \n",
    "            dbias_f_1, self.opt_m_bias_f_1, self.opt_v_bias_f_1    = adam_update(self.opt_m_bias_f_1, self.opt_v_bias_f_1, self.dbias_f_1, self.opt_beta1, self.opt_beta2, self.opt_t1)\n",
    "            self.bias_f_1 -= self.opt_eta * dbias_f_1 + self.bias_f_1 * self.lambda1 \n",
    "\n",
    "        \n",
    "    def backward2(self, x, y, output):\n",
    "       \n",
    "        self.e_f_2 = output - y\n",
    "\n",
    "        self.cbias_4[:, Aindx2Nrange(self.H_size, self.NU, 4)] = -self.beta1 * self.e_f_2.mm(self.Wb_f_2) \n",
    "        self.y_4 = self.z_4\n",
    "        self.y_4 = self.It2sta(self.Wr_4, self.y_4, self.bias_4 + self.cbias_4, self.t2sta)\n",
    "        self.e_4 = self.z_4 - self.y_4\n",
    "\n",
    "        # L3\n",
    "        self.cbias_3[:, Aindx2Nrange(self.H_size, self.NU, 3)] = -self.beta1 * self.e_4[:, Aindx2Nrange(self.H_size, self.NU, 6)].mm(self.Wb_3)\n",
    "        self.y_3 = self.z_3\n",
    "        self.y_3 = self.It2sta(self.Wr_3, self.y_3, self.bias_3 + self.cbias_3, self.t2sta)\n",
    "        self.e_3 = self.z_3 - self.y_3\n",
    "\n",
    "        ## \n",
    "        self.dWinX_2 = x.t().mm(self.e_3[:, Aindx2Nrange(self.H_size, self.NU, 5)]) / self.batch_size\n",
    "        self.dWin_3 = self.z_3[:, Aindx2Nrange(self.H_size, self.NU, 2)].t().mm(self.e_4[:, Aindx2Nrange(self.H_size, self.NU, 1)]) / self.batch_size\n",
    "        self.dWout_2 = self.z_4[:, Aindx2Nrange(self.H_size, self.NU, 3)].t().mm(self.e_f_2) / self.batch_size\n",
    "        self.dbias_f_2 = self.e_f_2.sum(0) / self.batch_size\n",
    "        \n",
    "        \n",
    "        if self.RNNLearning: \n",
    "            self.dWr_3 = self.z_3.t().mm(self.e_3) / self.batch_size\n",
    "            self.dWr_4 = self.z_4.t().mm(self.e_4) / self.batch_size   \n",
    "\n",
    "        if self.RNNBiasLearning:\n",
    "            self.dbias_3 = self.e_3.sum(0) / self.batch_size\n",
    "            self.dbias_4 = self.e_4.sum(0) / self.batch_size\n",
    "\n",
    "\n",
    "        self.opt_t2 += 1\n",
    "        dWinX_2, self.opt_m_WinX_2, self.opt_v_WinX_2    = adam_update(self.opt_m_WinX_2, self.opt_v_WinX_2, self.dWinX_2, self.opt_beta1, self.opt_beta2, self.opt_t2)\n",
    "        self.WinX_2 -= self.opt_eta * dWinX_2 + self.WinX_2 * self.lambda1\n",
    "        \n",
    "        dWin_3, self.opt_m_Win_3, self.opt_v_Win_3      = adam_update(self.opt_m_Win_3, self.opt_v_Win_3,   self.dWin_3, self.opt_beta1, self.opt_beta2, self.opt_t2)\n",
    "        self.Win_3 -= self.opt_eta * dWin_3 + self.Win_3 * self.lambda1 \n",
    "\n",
    "        dWout_2, self.opt_m_Wout_2, self.opt_v_Wout_2    = adam_update(self.opt_m_Wout_2, self.opt_v_Wout_2, self.dWout_2, self.opt_beta1, self.opt_beta2, self.opt_t2)\n",
    "        \n",
    "        self.Wout_2 -= self.opt_eta * dWout_2 + self.Wout_2 * self.lambda1 \n",
    "\n",
    "        if self.RNNLearning: \n",
    "            dWr_3, self.opt_m_Wr_3, self.opt_v_Wr_3         = adam_update(self.opt_m_Wr_3, self.opt_v_Wr_3,     self.dWr_3, self.opt_beta1, self.opt_beta2, self.opt_t2)\n",
    "            self.Wr_3 -= self.opt_eta * dWr_3 * self.Wr_3_s * self.alpha1 + self.Wr_3 * self.lambda1\n",
    "            dWr_4, self.opt_m_Wr_4, self.opt_v_Wr_4         = adam_update(self.opt_m_Wr_4, self.opt_v_Wr_4,     self.dWr_4, self.opt_beta1, self.opt_beta2, self.opt_t2)\n",
    "            self.Wr_4 -= self.opt_eta * dWr_4 * self.Wr_4_s * self.alpha1 + self.Wr_4 * self.lambda1\n",
    "\n",
    "        if self.RNNBiasLearning:\n",
    "            dbias_3, self.opt_m_b_3, self.opt_v_b_3         = adam_update(self.opt_m_b_3, self.opt_v_b_3,       self.dbias_3, self.opt_beta1, self.opt_beta2, self.opt_t2)\n",
    "            self.bias_3 -= self.opt_eta * dbias_3 + self.bias_3 * self.lambda1 \n",
    "            dbias_4, self.opt_m_b_4, self.opt_v_b_4         = adam_update(self.opt_m_b_4, self.opt_v_b_4,       self.dbias_4, self.opt_beta1, self.opt_beta2, self.opt_t2)\n",
    "            self.bias_4 -= self.opt_eta * dbias_4 + self.bias_4 * self.lambda1 \n",
    "\n",
    "            dbias_f_2, self.opt_m_bias_f_2, self.opt_v_bias_f_2    = adam_update(self.opt_m_bias_f_2, self.opt_v_bias_f_2, self.dbias_f_2, self.opt_beta1, self.opt_beta2, self.opt_t2)\n",
    "            self.bias_f_2 -= self.opt_eta * dbias_f_2 + self.bias_f_2 * self.lambda1 \n",
    "\n",
    "\n",
    "\n",
    "    def It2sta(self, Wr, h, bias, itsta):\n",
    "        \n",
    "        for indx in range(itsta):\n",
    "            h = self.f(h.mm(Wr)+bias)\n",
    "        \n",
    "        return h\n",
    "    \n",
    "    def It2staf(self, Wr, h, bias, itsta):\n",
    "\n",
    "        for indx in range(itsta):\n",
    "            h = (h.mm(Wr)+bias)\n",
    "        \n",
    "        return h\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7e17f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ###############################################################################\n",
    "# \n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.device = device\n",
    "        self.input_size = 28 * 28  # \n",
    "        self.num_classes = 10      # ~9ï¼‰\n",
    "        self.H_size = 1536     # Number of neurons in each hidden layer\n",
    "\n",
    "        self.NperU = 256 # Number of neurons in each block\n",
    "        self.NU = self.H_size // self.NperU \n",
    "        self.f = tanh\n",
    "        self.df = tanh_d\n",
    "\n",
    "        self.RNNCR = 0.25\n",
    "        self.RNNSR = 0.25\n",
    "        self.Feedforwardsc = 0.1\n",
    "        self.Feedbacksc = 0.5\n",
    "        self.t2sta = 8\n",
    "\n",
    "\n",
    "        self.num_epochs = 100      # training epochs\n",
    "        self.batch_size = 500     # batch size\n",
    "\n",
    "        self.learning_rate = 1e-3  # learning rate\n",
    "\n",
    "        self.alpha1 = 1e-4 # RNN weight updating coe\n",
    "        \n",
    "        self.lambda1 = 0e-5 # L2 regular\n",
    "        self.feedbackLearning = False\n",
    "        self.gamma1 = 0\n",
    "\n",
    "        self.RNNLearning = False ## whether the weights in RNN learn \n",
    "        self.RNNBiasLearning = False ## whether the bias is used\n",
    "\n",
    "\n",
    "config = Config()\n",
    "# \n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # \n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, transform=transform)\n",
    "\n",
    "train_loader1 = DataLoader(dataset=train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "test_loader1 = DataLoader(dataset=test_dataset, batch_size=config.batch_size, shuffle=False)\n",
    "train_loader1_gpu = [(data.to(device), target.to(device)) for data, target in train_loader1]\n",
    "test_loader1_gpu = [(data.to(device), target.to(device)) for data, target in test_loader1]\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform)\n",
    "\n",
    "train_loader2 = DataLoader(dataset=train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "test_loader2 = DataLoader(dataset=test_dataset, batch_size=config.batch_size, shuffle=False)\n",
    "train_loader2_gpu = [(data.to(device), target.to(device)) for data, target in train_loader2]\n",
    "test_loader2_gpu = [(data.to(device), target.to(device)) for data, target in test_loader2]\n",
    "\n",
    "\n",
    "\n",
    "res_path = Path(\"./Reusing/B\")\n",
    "res_path.mkdir(parents=True, exist_ok=True)\n",
    "taskinfo = f'FRNN_ML_PathB_RNNLearning{config.RNNLearning}'\n",
    "\n",
    "multitest = 5\n",
    "res = np.zeros((multitest,6,config.num_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31735ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for imultitest in range(multitest):\n",
    "    model = FRNN_ML4(config).to(device)\n",
    "\n",
    "\n",
    "    best_y_true = None\n",
    "    best_y_pred = None\n",
    "    ###### Training #######\n",
    "\n",
    "    for epoch in range(config.num_epochs):\n",
    "        losssum = 0\n",
    "        random.shuffle(train_loader1_gpu)\n",
    "        random.shuffle(train_loader2_gpu)\n",
    "        with tqdm(total=len(train_loader2_gpu), desc=f'Epoch {epoch + 1}/{config.num_epochs}: ', unit='batch', ncols=90, mininterval=1) as pbar:\n",
    "            for i, (images, labels) in enumerate(train_loader2_gpu):\n",
    "                # \n",
    "                images = images.view(-1, config.input_size)\n",
    "                labels_one_hot = one_hot(labels, config.num_classes)\n",
    "\n",
    "                # \n",
    "                outputs = model.forward2(images)\n",
    "\n",
    "                loss = cross_entropy_loss(outputs, labels_one_hot)\n",
    "                losssum += loss.item()\n",
    "                \n",
    "                ##\n",
    "                model.backward2(images, labels_one_hot, outputs)\n",
    "\n",
    "                pbar.set_postfix({'loss': f'{losssum/(i+1):.6f}'})  \n",
    "                pbar.update(1)\n",
    "        losssum = 0 \n",
    "        with tqdm(total=len(train_loader1_gpu), desc=f'Epoch {epoch + 1}/{config.num_epochs}: ', unit='batch', ncols=90, mininterval=1) as pbar:\n",
    "            for i, (images, labels) in enumerate(train_loader1_gpu):\n",
    "                # \n",
    "                images = images.view(-1, config.input_size)\n",
    "                labels_one_hot = one_hot(labels, config.num_classes)\n",
    "\n",
    "                # \n",
    "                outputs = model.forward1(images)\n",
    "\n",
    "                loss = cross_entropy_loss(outputs, labels_one_hot)\n",
    "                losssum += loss.item()\n",
    "                \n",
    "                ##\n",
    "                model.backward1(images, labels_one_hot, outputs)\n",
    "\n",
    "                pbar.set_postfix({'loss': f'{losssum/(i+1):.6f}'})  \n",
    "                pbar.update(1)\n",
    "\n",
    "\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        losssum = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in train_loader1_gpu:\n",
    "                images = images.view(-1, config.input_size)\n",
    "                labels_one_hot = one_hot(labels, config.num_classes)\n",
    "                outputs = model.forward1(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                loss = cross_entropy_loss(outputs, labels_one_hot)\n",
    "                losssum += loss.item()\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_accuracy = train_correct / train_total\n",
    "        \n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader1_gpu:\n",
    "                images = images.view(-1, config.input_size)\n",
    "                outputs = model.forward1(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                y_true.extend(labels.cpu().numpy())\n",
    "                y_pred.extend(predicted.cpu().numpy())\n",
    "                test_total += labels.size(0)\n",
    "                test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        test_accuracy = test_correct / test_total\n",
    "        res[imultitest][0][epoch] = losssum\n",
    "        res[imultitest][1][epoch] = train_accuracy\n",
    "        res[imultitest][2][epoch] = test_accuracy\n",
    "\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        losssum = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in train_loader2_gpu:\n",
    "                images = images.view(-1, config.input_size)\n",
    "                labels_one_hot = one_hot(labels, config.num_classes)\n",
    "                outputs = model.forward2(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                loss = cross_entropy_loss(outputs, labels_one_hot)\n",
    "                losssum += loss.item()\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_accuracy = train_correct / train_total\n",
    "        \n",
    "\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader2_gpu:\n",
    "                images = images.view(-1, config.input_size)\n",
    "                outputs = model.forward2(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                y_true.extend(labels.cpu().numpy())\n",
    "                y_pred.extend(predicted.cpu().numpy())\n",
    "                test_total += labels.size(0)\n",
    "                test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        test_accuracy = test_correct / test_total\n",
    "        res[imultitest][3][epoch] = losssum\n",
    "        res[imultitest][4][epoch] = train_accuracy\n",
    "        res[imultitest][5][epoch] = test_accuracy\n",
    "\n",
    "        # \n",
    "        current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "        print(f'\\t Loss: {res[imultitest][0][epoch] :.3f},\\t'\n",
    "            f'Train : {res[imultitest][1][epoch] * 100:.2f}%,\\t'\n",
    "            f'Test : {res[imultitest][2][epoch] * 100:.2f}%,\\t'\n",
    "            f'Loss: {res[imultitest][3][epoch] :.3f},\\t'\n",
    "            f'Train : {res[imultitest][4][epoch] * 100:.2f}%,\\t'\n",
    "            f'Test : {res[imultitest][5][epoch] * 100:.2f}%,\\t'\n",
    "            f'Current Time: {current_time}')\n",
    "\n",
    "    # best result\n",
    "    print(f\"{taskinfo} Time: {current_time}, Epochs: {config.num_epochs}, Learning Rate: {config.learning_rate}, \"\n",
    "        f\"FMNIST Best: {max(res[imultitest][1]) * 100:.2f}%  {max(res[imultitest][2]) * 100:.2f}%\\n\",\n",
    "        f\"MNIST Best: {max(res[imultitest][4]) * 100:.2f}%  {max(res[imultitest][5]) * 100:.2f}%\\n\")\n",
    "\n",
    "    current_time = time.strftime(\"%Y-%m-%d_%H%M%S\", time.localtime())\n",
    "\n",
    "    with open(res_path/\"res.txt\", \"a\") as f:\n",
    "        f.write(f\"{taskinfo} Time: {current_time}, Epochs: {config.num_epochs}, Learning Rate: {config.learning_rate}, \"\n",
    "        f\"FMNIST Best: {max(res[imultitest][1]) * 100:.2f}%  {max(res[imultitest][2]) * 100:.2f}%\\n\"\n",
    "        f\"MNIST Best: {max(res[imultitest][4]) * 100:.2f}%  {max(res[imultitest][5]) * 100:.2f}%\\n\")\n",
    "\n",
    "        for attr_name in dir(config):\n",
    "            if not attr_name.startswith('__') and not callable(getattr(config, attr_name)):  \n",
    "                attr_value = getattr(config, attr_name)\n",
    "                f.write(f'{attr_name}: {attr_value}  ')  \n",
    "        f.write(f'\\n\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47666593",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(res_path / f\"{taskinfo}_Time{current_time}\", res=res, taskinfo=taskinfo)\n",
    "tt = np.max(res[:,:,:], axis= -1)\n",
    "\n",
    "print(f\"\\n -------\\n Final mean {taskinfo} Time: {current_time}, Epochs: {config.num_epochs}, Learning Rate: {config.learning_rate}, \"\n",
    "        f\"FMNIST Best: {np.mean(tt[:,1],axis=0) * 100:.2f}%  {np.mean(tt[:,2],axis=0)* 100:.2f}%\\n\",\n",
    "        f\"MNIST Best: {np.mean(tt[:,4],axis=0) * 100:.2f}%  {np.mean(tt[:,5],axis=0) * 100:.2f}%\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
